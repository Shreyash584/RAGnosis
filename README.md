# RAGnosis ğŸ”ğŸ“„  
**LLM-powered Retrieval-Augmented Generation (RAG) System for Intelligent Document & Web Querying**

---

## ğŸ“Œ Project Overview
**RAGnosis** is an intelligent question-answering system built using **Large Language Models (LLMs)** and **Retrieval-Augmented Generation (RAG)** techniques.  
The system allows users to upload **PDF documents** and provide **URLs**, automatically extracts and indexes the content, and enables accurate, context-aware responses based strictly on the provided knowledge base.

Unlike generic chatbots, RAGnosis minimizes hallucinations by grounding responses in user-supplied data, making it suitable for research, academic, and enterprise use cases.

---

## ğŸ¯ Problem Statement
Traditional LLMs:
- Lack access to private or domain-specific documents
- Produce hallucinated or unverifiable answers
- Cannot efficiently scale to large document collections

**RAGnosis** addresses these limitations by:
- Combining semantic search with LLM reasoning
- Persistently storing document embeddings
- Answering queries only from trusted sources

---

## ğŸ§  Solution Approach (RAG Architecture)
1. **Data Ingestion**
   - PDFs are parsed and text is extracted
   - URLs are crawled and cleaned
2. **Chunking & Embeddings**
   - Documents are split into semantic chunks
   - Embeddings are generated using transformer-based models
3. **Vector Storage**
   - Embeddings are stored in a vector database (FAISS)
4. **Query Pipeline**
   - User query is embedded
   - Relevant chunks are retrieved via similarity search
   - Retrieved context is passed to the LLM for grounded answers

## ğŸ› ï¸ Tech Stack
### Backend
- **Python**
- **FastAPI** â€“ API backend
- **LangChain** â€“ RAG orchestration
- **FAISS** â€“ Vector similarity search
- **PyPDF** â€“ PDF parsing

### LLM & NLP
- **LLM via Ollama (Mistral / Phi-3)**
- **Transformer-based Embeddings**

### Frontend
- **HTML, CSS, JavaScript**
- Lightweight chat-style UI

---

## ğŸš€ Features
- ğŸ“„ Upload and query PDF documents
- ğŸŒ Query content from web URLs
- ğŸ§  Context-aware, grounded LLM responses
- ğŸ’¾ Persistent vector storage (no re-processing every run)
- âš¡ Fast and scalable semantic search
- ğŸ”’ Local LLM support for data privacy

---

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/Shreyash584/RAGnosis.git
cd RAGnosis
